{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567b491-3f32-4ec7-a4ea-f9d30faef693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets.quantum_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c32462-df27-4163-9edd-1d798d45c3a1",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f70a0b-347a-4aa5-8ec8-64392842d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "from scipy.stats import unitary_group\n",
    "\n",
    "from fastai.vision.all import DataLoaders\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader as DataLoader_torch\n",
    "\n",
    "import itertools\n",
    "from functools import reduce\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "142e46f9-0e2c-44c8-a256-db72713b99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import nbdev_export\n",
    "nbdev_export() # Export the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d057b71-d029-47ab-9b2c-b00aa017e98d",
   "metadata": {},
   "source": [
    "# State tomography class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee9fbd4-df60-4d04-a9de-c4a856e13cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class StateTomography(object):\n",
    "    \"\"\"\n",
    "    Creates various datasets corresponding to local and global measurements on\n",
    "    random mixed multi-qubit quantum states.\n",
    "\n",
    "    The input data is a `num_datapoints` times `num_measure` matrix where each\n",
    "    data point consists of `num_measure` measurements on a random `num_qubits`-\n",
    "    qubit density matrix.\n",
    "\n",
    "    Actions are all Pauli measurements and `num_random_actions` non-local and local \n",
    "    measurements, in total say, M measurements. The action data is a\n",
    "    `num_datapoint` times M matrix of measurement results on the random pauli\n",
    "    matrices of the input data. \n",
    "\n",
    "    The measurement bases for the generation of the input data can be saved in an\n",
    "    appropriate file, as well as the measurement bases of the actions.\n",
    "\n",
    "    The random density matrices can be saved in another appropriate file.\n",
    "\n",
    "    We can also save a hypothesis data file where specific local Pauli operators\n",
    "    are saved.\n",
    "\n",
    "    Args:\n",
    "        num_qubits (int): Number of qubits.\n",
    "        num_measure (int): Number of different measurements performed on each qubit.\n",
    "        num_random_actions (int): Number of additional random actions.\n",
    "        num_datapoints (int): Number of datapoints collected for each measurement set.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_qubits=2, num_measure=75, num_random_actions=20, num_datapoints=100000, test_data_points=100):\n",
    "        self.num_qubits = num_qubits\n",
    "        self.num_measure = num_measure\n",
    "        self.num_random_actions = num_random_actions\n",
    "        assert (self.num_random_actions/(self.num_qubits+1)).is_integer()\n",
    "        self.num_datapoints = num_datapoints\n",
    "        \n",
    "        self.measurements = self._create_measurements()\n",
    "\n",
    "        self.paulis = [np.eye(2, dtype=complex), \n",
    "                       np.array([[0,1],[1,0]],dtype=complex), # X\n",
    "                       np.array([[0,-1j],[1j,0]],dtype=complex), # Y\n",
    "                       np.array([[1,0],[0,-1]],dtype=complex) # Z\n",
    "                       ]\n",
    "        \n",
    "        self.num_actions = len(self.paulis)**self.num_qubits-1+self.num_random_actions\n",
    "        self.num_test_datapoints=test_data_points ##########\n",
    "        self.create_dataset()\n",
    "        self.get_test_data()\n",
    "        # self.data = DataHandler(self.num_qubits+1, datasets=raw_data)\n",
    "\n",
    "    def create_dataset(self):\n",
    "        \"\"\"\n",
    "        Creates one input dataset corresponding to a full tomography and one \n",
    "        action dataset corresponding to the expectation value of one measurement per action.\n",
    "        Also keeps track of the density matrices that are randomly generated for this data.\n",
    "        \"\"\"\n",
    "        # input data\n",
    "        self.input_data = np.empty((self.num_datapoints, self.num_measure))\n",
    "        self.true_data = np.empty((self.num_datapoints, 2**self.num_qubits, 2**self.num_qubits), dtype=complex)\n",
    "        for l in range(self.num_datapoints):\n",
    "            rho = self._random_mixed_state()\n",
    "            \n",
    "        \n",
    "            self.input_data[l] = self._create_datapoint(rho)\n",
    "            self.true_data[l] = rho\n",
    "            # generate input data\n",
    "        \n",
    "        # action performed on data\n",
    "        self.action_measures = np.empty((len(self.paulis)**self.num_qubits-1+self.num_random_actions, 2**self.num_qubits, 2**self.num_qubits),dtype=complex) #TODO\n",
    "        self.action_data = np.empty((self.num_datapoints, \n",
    "                                     len(self.paulis)**self.num_qubits-1+self.num_random_actions,\n",
    "                                     1))\n",
    "        \n",
    "        for i, rho in enumerate(self.true_data):\n",
    "            j = 0\n",
    "            for action in product(range(len(self.paulis)), repeat=self.num_qubits):\n",
    "                if action==tuple(0 for i in range(self.num_qubits)):\n",
    "                    continue\n",
    "                # define projector from paulis\n",
    "                multi_op = [np.eye(2) for k in range(self.num_qubits)]\n",
    "                for index, a in enumerate(action):\n",
    "                    multi_op[index] = self.paulis[a]\n",
    "                proj = 1/2*(reduce(np.kron, [np.eye(2) for k in range(self.num_qubits)]) + reduce(np.kron, multi_op))\n",
    "                self.action_data[i, j] = self._measure(rho, proj)\n",
    "                # print(self.action_data[i,j])\n",
    "                # save projector\n",
    "                if i==0:\n",
    "                    self.action_measures[j] = proj\n",
    "                j+=1\n",
    "            # add random projectors\n",
    "            if i==0:\n",
    "                # define random measurements\n",
    "                proj_set = self._create_measurements()[0:int(self.num_random_actions/(self.num_qubits+1))]\n",
    "                for s in range(self.num_qubits):\n",
    "                    proj_set = np.append(proj_set, self._create_measurements(local=s)[0:int(self.num_random_actions/(self.num_qubits+1))], axis=0)\n",
    "                self.action_measures[j:len(self.action_measures)] = proj_set\n",
    "            for p in self.action_measures[j:len(self.action_measures)]:\n",
    "                self.action_data[i, j] = self._measure(rho, p)\n",
    "                j+=1\n",
    "\n",
    "\n",
    "    def get_test_data(self):\n",
    "\n",
    "        pauli_mats = [np.array([[0,1],[1,0]], dtype=complex), # pauli-x\n",
    "                              np.array([[0,-1.j],[1.j,0]], dtype=complex), # pauli-y\n",
    "                              np.array([[1,0],[0,-1]], dtype=complex) # pauli-z\n",
    "                             ]\n",
    "        axis = 3 # x,y,z\n",
    "        num_datapoint = 11 # -1., -0.8, ..., 0.8, 1.\n",
    "        data = torch.empty((self.num_qubits, axis, num_datapoint, self.num_measure * (self.num_qubits + 1)))\n",
    "        \n",
    "        \n",
    "        self.datapoints = torch.empty((2**(2*self.num_qubits)-1, num_datapoint, self.num_measure))#### should be 2**(2*self.num_qubits)-1 \n",
    "        \n",
    "        # generate data: for each qubit, one density matrix with variable amplitudes of one pauli matrix in Bloch rep\n",
    "        \n",
    "        for idxa, action in enumerate(itertools.product(range(len(self.paulis)), repeat=self.num_qubits)):\n",
    "        \n",
    "        # for a, action in enumerate(range(len(self.paulis)), repeat=self.num_qubits):\n",
    "            if idxa!=0:\n",
    "        \n",
    "                if action==tuple(0 for i in range(self.num_qubits)):\n",
    "                    continue\n",
    "                # define densities from paulis\n",
    "                multi_op = [np.eye(2) for k in range(self.num_qubits)]\n",
    "                for index, a in enumerate(action):\n",
    "                    multi_op[index] = self.paulis[a]\n",
    "        \n",
    "                for ind,r in enumerate(np.arange(-1., 1.2, 0.2)):\n",
    "                    rho = 1/4*(reduce(np.kron, [np.eye(2) for k in range(self.num_qubits)]) + r*reduce(np.kron, multi_op))\n",
    "                    self.datapoints[idxa-1,ind] = self._create_datapoint(rho)\n",
    "    \n",
    "    \n",
    "    # return datapoints\n",
    "    \n",
    "                \n",
    "    def get_training_data(self, repeat = False):\n",
    "        ''' \n",
    "        Outputs the data in the correct shape for the AE training. To understand the shapes:\n",
    "        N: num_datapoints   |   K: num_measures   |   A: num_actions\n",
    "        As the data is created in such a way that for each state, all actions are applied, the\n",
    "        input is create by repeating A times the K measures over the N states. Then, we have the following\n",
    "        shapes:\n",
    "        - Input: if repeat: N x A x K ; else: N x K\n",
    "        - Output: N x A\n",
    "        '''\n",
    "\n",
    "\n",
    "        if repeat:\n",
    "            return np.repeat(self.input_data[:, np.newaxis, :], self.num_actions, axis=1), self.action_data.squeeze(axis = -1)\n",
    "        else:\n",
    "            return self.input_data, self.action_data.squeeze(axis = -1), self.action_measures#, self.datapoints\n",
    "    \n",
    "\n",
    "    def save_truth(self, file_name):\n",
    "        \"\"\"\n",
    "        Saves the true state underlying the data.\n",
    "        \"\"\"\n",
    "        torch.save(torch.from_numpy(self.true_data), 'data/' + file_name + '.pth')\n",
    "\n",
    "    def save_measurements(self, file_name):\n",
    "        \"\"\"\n",
    "        Saves the measurement bases that were used to generate the data.\n",
    "        \"\"\"\n",
    "        torch.save(torch.from_numpy(self.measurements), 'data/' + file_name + '_input.pth')\n",
    "        torch.save(torch.from_numpy(self.action_measures), 'data/' + file_name + '_actions.pth')\n",
    "\n",
    "    def save_data(self, file_name):\n",
    "        \"\"\"\n",
    "        Saves the input and action data separately.\n",
    "        \"\"\"\n",
    "        torch.save(torch.from_numpy(self.input_data), 'data/' + file_name + '_input.pth')\n",
    "        torch.save(torch.from_numpy(self.action_data), 'data/' + file_name + '_action.pth')\n",
    "\n",
    "    \n",
    "    def save_hypothesis(self):\n",
    "        \"\"\"\n",
    "        Creates and saves data for hypothesis testing of a representation.\n",
    "\n",
    "        For each qubit we generate a density matrix\n",
    "\n",
    "        ..math::\n",
    "            \\rho = \\frac{1}{2}(I + \\vec{a}\\vec{\\sigma})\n",
    "\n",
    "        and set :math:`\\vec{a}=(x,0,0),(0,y,0),(0,0,z)` where we vary x,y,z\n",
    "        between -1 and 1 in 0.2 steps.\n",
    "        \"\"\"\n",
    "        # pauli matrices for Bloch representation\n",
    "        pauli_mats = [np.array([[0,1],[1,0]], dtype=complex), # pauli-x\n",
    "                      np.array([[0,-1.j],[1.j,0]], dtype=complex), # pauli-y\n",
    "                      np.array([[1,0],[0,-1]], dtype=complex) # pauli-z\n",
    "                     ]\n",
    "        axis = 3 # x,y,z\n",
    "        num_datapoint = 11 # -1., -0.8, ..., 0.8, 1.\n",
    "        data = torch.empty((self.num_qubits, axis, num_datapoint, self.num_measure * (self.num_qubits + 1)))\n",
    "        # generate data: for each qubit, one density matrix with variable amplitudes of one pauli matrix in Bloch rep\n",
    "        for q in range(self.num_qubits):\n",
    "            for axis, pauli in enumerate(self.paulis[1:]):\n",
    "                for index, var in enumerate(np.arange(-1., 1.2, 0.2)):\n",
    "                    # create test density matrix\n",
    "                    rho = [1/2*np.eye(2) for q in range(self.num_qubits)]\n",
    "                    local_rho = 1/2* (np.eye(2) + var * pauli)\n",
    "                    rho[q] = local_rho\n",
    "                    rho = reduce(np.kron, rho)\n",
    "\n",
    "                    # create datapoint\n",
    "                    datapoint = self._create_datapoint(rho)\n",
    "                    # restructure datapoint\n",
    "                    local_measure = torch.zeros(self.num_measure * (self.num_qubits+1))\n",
    "                    local_measure[self.num_measure * q:self.num_measure * (q+1)] = datapoint[q]\n",
    "                    #add data\n",
    "                    data[q,axis,index] = local_measure\n",
    "\n",
    "        # return datapoint\n",
    "        # save data\n",
    "        torch.save(data, 'data/' + file_name + '.pth')\n",
    "    \n",
    "    # ----------------- helper methods -----------------------------------------\n",
    "\n",
    "    # def test_data(self):\n",
    "        \n",
    "\n",
    "    def _create_datapoint(self, rho):\n",
    "        \"\"\"\n",
    "        Creates one datapoint consisting of measurement results for some \n",
    "        pre-specified bases on a input density matrix. \n",
    "\n",
    "        Args:\n",
    "            rho (np.ndarray): Input density matrix.\n",
    "\n",
    "        Returns:\n",
    "            datapoint (torch.Tensor): Datapoint of size (#measurements)\n",
    "        \"\"\"\n",
    "        # empty datapoint. For each set of local and global projection, we collect a datapoint.\n",
    "        datapoint = torch.empty((self.num_measure))\n",
    "        \n",
    "        # collect collective measurements\n",
    "        for j in range(self.num_measure):\n",
    "            datapoint[j] = self._measure(rho, self.measurements[j])\n",
    "\n",
    "        return datapoint\n",
    "\n",
    "    def _measure(self, rho, projection):\n",
    "        \"\"\"\n",
    "        Measures the density matrix `rho` with `projection`.\n",
    "\n",
    "        Returns: \n",
    "            result (float): Probabiltiy to measure `projection`.\n",
    "        \"\"\"\n",
    "        result = np.trace(rho@projection)\n",
    "        \n",
    "        assert(np.imag(result) < 1e-3)\n",
    "        return np.real(result)\n",
    "\n",
    "    def _create_measurements(self, local=None):\n",
    "        \"\"\"\n",
    "        Creates the set of all measurements for the state tomography on the input state.\n",
    "\n",
    "        Returns:\n",
    "            measurements (np.ndarray): The projections that form the measurements.\n",
    "        \"\"\"\n",
    "        measurements = np.empty((self.num_measure, 2**self.num_qubits, 2**self.num_qubits),dtype=complex)\n",
    "\n",
    "        if local==None:\n",
    "            for j in range(self.num_measure):\n",
    "                state = unitary_group.rvs(2**self.num_qubits)[:, 0]\n",
    "                \n",
    "                proj = np.outer(state.conj(), state)\n",
    "                measurements[j] = proj\n",
    "        else:\n",
    "            for j in range(self.num_measure):\n",
    "                state = unitary_group.rvs(2)[:, 0]\n",
    "                \n",
    "                proj = np.outer(state.conj(), state)\n",
    "                full_proj = [np.eye(2) for q in range(self.num_qubits)]\n",
    "                full_proj[local] = proj\n",
    "                measurements[j] = reduce(np.kron, full_proj)\n",
    "        \n",
    "        return measurements\n",
    "\n",
    "    def _random_mixed_state(self):\n",
    "        \"\"\"\n",
    "        Draws a random mixed state as the partial trace of a pure state.\n",
    "\n",
    "        Returns:\n",
    "            mixed_rho (np.ndarray): The random mixed state.\n",
    "        \"\"\"\n",
    "        pure_state = unitary_group.rvs(2 * 2**self.num_qubits)[:, 0]\n",
    "        pure_rho = np.outer(pure_state.conj(), pure_state)\n",
    "        mixed_rho = np.trace(\n",
    "                             pure_rho.reshape(\n",
    "                                              2**self.num_qubits, \n",
    "                                              2, \n",
    "                                              2**self.num_qubits, \n",
    "                                              2), \n",
    "                             axis1=1, \n",
    "                             axis2=3\n",
    "                            )\n",
    "        return mixed_rho\n",
    "    \n",
    "    def _acted_qbit(self):\n",
    "        ''' Returns a list to know, for the Pauli gates, to which qbit they acted\n",
    "        0 means to none | 3 means to both\n",
    "        '''\n",
    "        \n",
    "        acted = [0]\n",
    "        for idx, action in enumerate(product(range(len(self.paulis)), repeat=self.num_qubits)):\n",
    "            if idx == 0:\n",
    "                continue\n",
    "                \n",
    "            if action[0] == 0:\n",
    "                acted.append(1)\n",
    "            elif action[1] == 0:\n",
    "                acted.append(2)\n",
    "            else:\n",
    "                acted.append(3)           \n",
    "\n",
    "        return acted\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b80eac-47e3-45e1-bcdd-e45bc8cd7b31",
   "metadata": {},
   "source": [
    "# Training dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c90bfe0-1862-4b82-883f-bed09dbb6c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_quantum_dataset(tomography, batch_size, device = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "\n",
    "    # Generate the dataset\n",
    "    inputs, outputs, actions = tomography.get_training_data()\n",
    "\n",
    "    # Action representatio \n",
    "    complex_act = torch.tensor(actions)\n",
    "\n",
    "    # Separate real and imaginary parts for each (4, 4) matrix in the batch\n",
    "    real_part = complex_act.real  # Shape: (24, 4, 4)\n",
    "    imag_part = complex_act.imag  # Shape: (24, 4, 4)\n",
    "\n",
    "    # Flatten each (4, 4) matrix into (16,) for real and imaginary parts\n",
    "    real_flattened = real_part.view(15, -1)  # Shape: (24, 16)\n",
    "    imag_flattened = imag_part.view(15, -1)  # Shape: (24, 16)\n",
    "\n",
    "    # Stack real and imaginary parts along the last dimension to get shape (24, 32)\n",
    "    action_rep = torch.cat([real_flattened, imag_flattened], dim=1).to(torch.float)  # Shape: (24, 32)\n",
    "\n",
    "    # Repeat actions and states to stack them\n",
    "    inputs_r = torch.repeat_interleave(torch.tensor(inputs, dtype = torch.float), \n",
    "                                        repeats = tomography.num_actions,\n",
    "                                        dim = 0)\n",
    "\n",
    "    action_r = action_rep.repeat(tomography.num_datapoints, 1)\n",
    "\n",
    "    # Merge the inputs and actions\n",
    "    merged_input = torch.hstack((inputs_r, action_r))\n",
    "\n",
    "    # Create torch / fastai dataloaders\n",
    "    train_size = int(merged_input.shape[0]*0.8)\n",
    "\n",
    "    dataset = TensorDataset(merged_input[:train_size].to(device), \n",
    "                            torch.tensor(outputs.flatten()[:train_size], dtype = torch.float).to(device))\n",
    "    loader = DataLoader_torch(dataset, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "    dataset_test = TensorDataset(merged_input[train_size:].to(device), \n",
    "                                torch.tensor(outputs.flatten()[train_size:], dtype = torch.float).to(device))\n",
    "    loader_test = DataLoader_torch(dataset_test, batch_size = 2000, shuffle=True)\n",
    "\n",
    "    return DataLoaders(loader, loader_test), loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59312c30-aafe-4d72-88c3-363c4b854241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_258171/1988250523.py:64: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  self.input_data[l] = self._create_datapoint(rho)\n"
     ]
    }
   ],
   "source": [
    "tomography = StateTomography(num_qubits=2,\n",
    "                             num_measure = 75, \n",
    "                             num_random_actions= 0,\n",
    "                             num_datapoints = 10) \n",
    "\n",
    "data, loader = generate_quantum_dataset(tomography, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ae3ef6-798e-4cb3-8ff1-8570d7c5928d",
   "metadata": {},
   "source": [
    "# Test dataset $\\rho(r)$ generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa5e31b-c5c0-4243-9808-3a94b95bb122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_test_data(tomography, num_datapoint = 100):        \n",
    "    \n",
    "    datapoints = torch.empty((2**(2*tomography.num_qubits)-1, num_datapoint, tomography.num_measure))\n",
    "    \n",
    "    rho_points = torch.empty((2**(2*tomography.num_qubits)-1, num_datapoint, 2**(tomography.num_qubits),2**(tomography.num_qubits)))\n",
    "\n",
    "    # generate data: for each qubit, one density matrix with variable amplitudes of one pauli matrix in Bloch rep\n",
    "    \n",
    "    for idxa, action in enumerate(itertools.product(range(len(tomography.paulis)), repeat=tomography.num_qubits)):\n",
    "        \n",
    "        if idxa!=0:\n",
    "    \n",
    "            if action==tuple(0 for i in range(tomography.num_qubits)):\n",
    "                continue\n",
    "            # define densities from paulis\n",
    "            multi_op = [np.eye(2) for k in range(tomography.num_qubits)]\n",
    "            for index, a in enumerate(action):\n",
    "                multi_op[index] = tomography.paulis[a]\n",
    "    \n",
    "            for ind, r in enumerate(np.linspace(-1., 1, num_datapoint)):\n",
    "                rho = 1/4*(reduce(np.kron, [np.eye(2) for k in range(tomography.num_qubits)]) + r*reduce(np.kron, multi_op))\n",
    "                datapoints[idxa-1,ind] = tomography._create_datapoint(rho)\n",
    "                \n",
    "                rho_points[idxa-1,ind] = torch.tensor(rho)\n",
    "    \n",
    "    \n",
    "    return datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c6d5ea2-4a74-4262-a7d3-8b55e6badd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 5, 75])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomography = StateTomography(num_qubits = 2,\n",
    "                             num_measure = 75, \n",
    "                             num_random_actions = 0,\n",
    "                             num_datapoints = 10)\n",
    "\n",
    "test_data = get_test_data(tomography, num_datapoint = 5)\n",
    "test_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air",
   "language": "python",
   "name": "air"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
